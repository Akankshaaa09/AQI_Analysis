{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2FeSud57M86m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('city_day.csv')\n",
        "# Reading the dataset"
      ],
      "metadata": {
        "id": "BRysxZvuNEDC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "# Loading the dataset"
      ],
      "metadata": {
        "id": "MYR_cwcONRze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "UXiNwS7DNWuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "# Checking the over all information on the dataset."
      ],
      "metadata": {
        "id": "KcWEhjy7Pszj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n",
        "# There are a lot of missing values present in the dataset"
      ],
      "metadata": {
        "id": "VDeY1okmPu55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n",
        "# Checking the descriptive stats of the numeric values present in the data like mean, standard deviation, min values and max value present in the data"
      ],
      "metadata": {
        "id": "rOsg-8eSPx23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()\n",
        "# These are all the unique values present in the dataframe"
      ],
      "metadata": {
        "id": "STAHTIiuP0G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n",
        "# These are all the columns present in the dataset."
      ],
      "metadata": {
        "id": "g_IWFEsGP2P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data=df)"
      ],
      "metadata": {
        "id": "_JfHCFiuQPJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['City'].value_counts()\n",
        "# Viewing the count of values present in the state column\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.xticks(rotation=90)\n",
        "df.City.hist()\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Frequencies')\n",
        "plt.plot()\n",
        "# The visualization shows us the count of states present in the dataset.\n"
      ],
      "metadata": {
        "id": "iZvufADtP_nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30, 10))\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x='City',y='PM2.5',data=df);\n",
        "# This visualization shows the name of the state having higher PM2.5 levels in the air which is Patna"
      ],
      "metadata": {
        "id": "xv9eXJOtQXA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize']=(30,10)"
      ],
      "metadata": {
        "id": "JeCx0aW3QZob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['PM2.5','City']].groupby([\"City\"]).mean().sort_values(by='PM2.5').plot.bar(color='purple')\n",
        "plt.show()\n",
        "# We can also use the groupby function to sort values in an ascending order based on the x-axis, y-axis and its keys\n",
        "# Below we get a clear picture of the states in an increasing order based on their PM2.5 levels."
      ],
      "metadata": {
        "id": "qyCUmtxlQb33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30, 10))\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x='City',y='PM10',data=df);\n",
        "# Delhi has a higher PM10 level compared to other states"
      ],
      "metadata": {
        "id": "yDe1Bt6VQeWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['PM10','City']].groupby([\"City\"]).mean().sort_values(by='PM10').plot.bar(color='purple')\n",
        "plt.show()\n",
        "# We can also use the groupby function to sort values in an ascending order based on the x-axis, y-axis and its keys\n",
        "# Below we get a clear picture of the states in an increasing order based on their PM10 levels."
      ],
      "metadata": {
        "id": "OQzWXhx_QgPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30, 10))\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x='City',y='SO2',data=df);\n",
        "# Ahmedabad has higher so2 level compared to other states"
      ],
      "metadata": {
        "id": "T7FDX8mRQiDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30, 10))\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x='City',y='NOx',data=df);\n",
        "# Kochi has higher NOx level compared to other states"
      ],
      "metadata": {
        "id": "eE1xfWN7Qku3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30, 10))\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x='City',y='NH3',data=df);\n",
        "# Chennai has higher NH3 level compared to other states"
      ],
      "metadata": {
        "id": "EYJQE1ExQnBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30, 10))\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x='City',y='CO',data=df);\n",
        "# Ahmedabad has higher CO level compared to other states"
      ],
      "metadata": {
        "id": "w-H1EnifhQWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30, 10))\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x='City',y='O3',data=df);\n",
        "# Bhopal has higher O3 level compared to other states"
      ],
      "metadata": {
        "id": "_K9HrVxrhah5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30, 10))\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x='City',y='AQI',data=df)"
      ],
      "metadata": {
        "id": "SO4g43A2Qkeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nullvalues = df.isnull().sum().sort_values(ascending=False)\n",
        "# Checking all null values"
      ],
      "metadata": {
        "id": "qmvZ-7m2Qpuf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nullvalues"
      ],
      "metadata": {
        "id": "5LY5rmmEQrj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n",
        "# Now checking the null values"
      ],
      "metadata": {
        "id": "IVYqs0IEQ0K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "HxfnSV9KQ3Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(0, inplace=True)\n",
        "# null values are replaced with zeros for the numerical data"
      ],
      "metadata": {
        "id": "sqQOzUM-Q6jC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n",
        "# Now we have successfully imputed null values which were present in the dataset"
      ],
      "metadata": {
        "id": "ORBUZNjqQ8a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "e6o-MuDtQ9Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"PM10_24hr_avg\"] = df.groupby(\"City\")[\"PM10\"].rolling(window = 24, min_periods = 16).mean().values\n",
        "df[\"PM2.5_24hr_avg\"] = df.groupby(\"City\")[\"PM2.5\"].rolling(window = 24, min_periods = 16).mean().values\n",
        "df[\"SO2_24hr_avg\"] = df.groupby(\"City\")[\"SO2\"].rolling(window = 24, min_periods = 16).mean().values\n",
        "df[\"NOx_24hr_avg\"] = df.groupby(\"City\")[\"NOx\"].rolling(window = 24, min_periods = 16).mean().values\n",
        "df[\"NH3_24hr_avg\"] = df.groupby(\"City\")[\"NH3\"].rolling(window = 24, min_periods = 16).mean().values\n",
        "df[\"CO_8hr_max\"] = df.groupby(\"City\")[\"CO\"].rolling(window = 8, min_periods = 1).max().values\n",
        "df[\"O3_8hr_max\"] = df.groupby(\"City\")[\"O3\"].rolling(window = 8, min_periods = 1).max().values"
      ],
      "metadata": {
        "id": "39XEse3ul_yi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(0, inplace=True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "frBvTN8pGaPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "wx_YZjber8IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_PM25_subindex(x):\n",
        "    if x <= 30:\n",
        "        return x * 50 / 30\n",
        "    elif x <= 60:\n",
        "        return 50 + (x - 30) * 50 / 30\n",
        "    elif x <= 90:\n",
        "        return 100 + (x - 60) * 100 / 30\n",
        "    elif x <= 120:\n",
        "        return 200 + (x - 90) * 100 / 30\n",
        "    elif x <= 250:\n",
        "        return 300 + (x - 120) * 100 / 130\n",
        "    elif x > 250:\n",
        "        return 400 + (x - 250) * 100 / 130\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df[\"PM2.5_SubIndex\"] = df[\"PM2.5_24hr_avg\"].apply(lambda x: get_PM25_subindex(x))\n",
        "data= df[['PM2.5_24hr_avg','PM2.5_SubIndex']]\n",
        "data.head()\n",
        "\n",
        "# calculating the individual pollutant index for so2(sulphur dioxide)"
      ],
      "metadata": {
        "id": "oONWBOMJRCEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "a0SfdSMlB-XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## PM10 Sub-Index calculation\n",
        "def get_PM10_subindex(x):\n",
        "    if x <= 50:\n",
        "        return x\n",
        "    elif x <= 100:\n",
        "        return x\n",
        "    elif x <= 250:\n",
        "        return 100 + (x - 100) * 100 / 150\n",
        "    elif x <= 350:\n",
        "        return 200 + (x - 250)\n",
        "    elif x <= 430:\n",
        "        return 300 + (x - 350) * 100 / 80\n",
        "    elif x > 430:\n",
        "        return 400 + (x - 430) * 100 / 80\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df[\"PM10_SubIndex\"] = df[\"PM10_24hr_avg\"].apply(lambda x: get_PM10_subindex(x))\n",
        "data= df[['PM10_24hr_avg','PM10_SubIndex']]\n",
        "data.head()\n",
        "# calculating the individual pollutant index for PM10"
      ],
      "metadata": {
        "id": "azafIc-zREN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "JYyhFPm9CacU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SO2 Sub-Index calculation\n",
        "def get_SO2_subindex(x):\n",
        "    if x <= 40:\n",
        "        return x * 50 / 40\n",
        "    elif x <= 80:\n",
        "        return 50 + (x - 40) * 50 / 40\n",
        "    elif x <= 380:\n",
        "        return 100 + (x - 80) * 100 / 300\n",
        "    elif x <= 800:\n",
        "        return 200 + (x - 380) * 100 / 420\n",
        "    elif x <= 1600:\n",
        "        return 300 + (x - 800) * 100 / 800\n",
        "    elif x > 1600:\n",
        "        return 400 + (x - 1600) * 100 / 800\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df[\"SO2_SubIndex\"] = df[\"SO2_24hr_avg\"].apply(lambda x: get_SO2_subindex(x))\n",
        "data= df[['SO2_24hr_avg','SO2_SubIndex']]\n",
        "data.head()\n",
        "# calculating the individual pollutant index for so2"
      ],
      "metadata": {
        "id": "v4n_fOyHRGH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "pWPfl6COCuTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NOx Sub-Index calculation\n",
        "def get_NOx_subindex(x):\n",
        "    if x <= 40:\n",
        "        return x * 50 / 40\n",
        "    elif x <= 80:\n",
        "        return 50 + (x - 40) * 50 / 40\n",
        "    elif x <= 180:\n",
        "        return 100 + (x - 80) * 100 / 100\n",
        "    elif x <= 280:\n",
        "        return 200 + (x - 180) * 100 / 100\n",
        "    elif x <= 400:\n",
        "        return 300 + (x - 280) * 100 / 120\n",
        "    elif x > 400:\n",
        "        return 400 + (x - 400) * 100 / 120\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df[\"NOx_SubIndex\"] = df[\"NOx_24hr_avg\"].apply(lambda x: get_NOx_subindex(x))\n",
        "data= df[['NOx_24hr_avg','NOx_SubIndex']]\n",
        "data.head()\n",
        "# calculating the individual pollutant index for nox"
      ],
      "metadata": {
        "id": "6AsRlKjDRH8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "i8zjbytjC_Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NH3 Sub-Index calculation\n",
        "def get_NH3_subindex(x):\n",
        "    if x <= 200:\n",
        "        return x * 50 / 200\n",
        "    elif x <= 400:\n",
        "        return 50 + (x - 200) * 50 / 200\n",
        "    elif x <= 800:\n",
        "        return 100 + (x - 400) * 100 / 400\n",
        "    elif x <= 1200:\n",
        "        return 200 + (x - 800) * 100 / 400\n",
        "    elif x <= 1800:\n",
        "        return 300 + (x - 1200) * 100 / 600\n",
        "    elif x > 1800:\n",
        "        return 400 + (x - 1800) * 100 / 600\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df[\"NH3_SubIndex\"] = df[\"NH3_24hr_avg\"].apply(lambda x: get_NH3_subindex(x))\n",
        "data= df[['NH3_24hr_avg','NH3_SubIndex']]\n",
        "data.head()\n",
        "# calculating the individual pollutant index for nh3"
      ],
      "metadata": {
        "id": "9A3dT3pfDE1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "GBY4HD46DN7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## CO Sub-Index calculation\n",
        "def get_CO_subindex(x):\n",
        "    if x <= 1:\n",
        "        return x * 50 / 1\n",
        "    elif x <= 2:\n",
        "        return 50 + (x - 1) * 50 / 1\n",
        "    elif x <= 10:\n",
        "        return 100 + (x - 2) * 100 / 8\n",
        "    elif x <= 17:\n",
        "        return 200 + (x - 10) * 100 / 7\n",
        "    elif x <= 34:\n",
        "        return 300 + (x - 17) * 100 / 17\n",
        "    elif x > 34:\n",
        "        return 400 + (x - 34) * 100 / 17\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df[\"CO_SubIndex\"] = df[\"CO_8hr_max\"].apply(lambda x: get_CO_subindex(x))\n",
        "data= df[['CO_8hr_max','CO_SubIndex']]\n",
        "data.head()\n",
        "# calculating the individual pollutant index for co"
      ],
      "metadata": {
        "id": "q7IlPSiRDQZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "Evk2Qk8sDlqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## O3 Sub-Index calculation\n",
        "def get_O3_subindex(x):\n",
        "    if x <= 50:\n",
        "        return x * 50 / 50\n",
        "    elif x <= 100:\n",
        "        return 50 + (x - 50) * 50 / 50\n",
        "    elif x <= 168:\n",
        "        return 100 + (x - 100) * 100 / 68\n",
        "    elif x <= 208:\n",
        "        return 200 + (x - 168) * 100 / 40\n",
        "    elif x <= 748:\n",
        "        return 300 + (x - 208) * 100 / 539\n",
        "    elif x > 748:\n",
        "        return 400 + (x - 400) * 100 / 539\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df[\"O3_SubIndex\"] = df[\"O3_8hr_max\"].apply(lambda x: get_O3_subindex(x))\n",
        "data= df[['O3_8hr_max','O3_SubIndex']]\n",
        "data.head()\n",
        "# calculating the individual pollutant index for o3"
      ],
      "metadata": {
        "id": "u-DqL_D8DoQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "85BunilDD1jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## AQI bucketing\n",
        "def get_AQI_bucket(x):\n",
        "    if x <= 50:\n",
        "        return \"Good\"\n",
        "    elif x <= 100:\n",
        "        return \"Satisfactory\"\n",
        "    elif x <= 200:\n",
        "        return \"Moderate\"\n",
        "    elif x <= 300:\n",
        "        return \"Poor\"\n",
        "    elif x <= 400:\n",
        "        return \"Very Poor\"\n",
        "    elif x > 400:\n",
        "        return \"Severe\"\n",
        "    else:\n",
        "        return np.NaN\n",
        "\n",
        "df[\"Checks\"] = (df[\"PM2.5_SubIndex\"] > 0).astype(int) + \\\n",
        "                (df[\"PM10_SubIndex\"] > 0).astype(int) + \\\n",
        "                (df[\"SO2_SubIndex\"] > 0).astype(int) + \\\n",
        "                (df[\"NOx_SubIndex\"] > 0).astype(int) + \\\n",
        "                (df[\"NH3_SubIndex\"] > 0).astype(int) + \\\n",
        "                (df[\"CO_SubIndex\"] > 0).astype(int) + \\\n",
        "                (df[\"O3_SubIndex\"] > 0).astype(int)\n",
        "\n",
        "df[\"AQI_calculated\"] = round(df[[\"PM2.5_SubIndex\", \"PM10_SubIndex\", \"SO2_SubIndex\", \"NOx_SubIndex\",\n",
        "                                 \"NH3_SubIndex\", \"CO_SubIndex\", \"O3_SubIndex\"]].max(axis = 1))\n",
        "df.loc[df[\"PM2.5_SubIndex\"] + df[\"PM10_SubIndex\"] <= 0, \"AQI_calculated\"] = np.NaN\n",
        "df.loc[df.Checks < 3, \"AQI_calculated\"] = np.NaN\n",
        "\n",
        "df[\"AQI_bucket_calculated\"] = df[\"AQI_calculated\"].apply(lambda x: get_AQI_bucket(x))\n",
        "df[~df.AQI_calculated.isna()].head(13)\n",
        "# Caluclating the Air Quality Index."
      ],
      "metadata": {
        "id": "cR_BU2wBRJuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replacement_text = 'N/A'\n",
        "df['AQI_bucket_calculated'].fillna(replacement_text, inplace=True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "2wxJq5rFL0Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(0, inplace=True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "lU5TRkJELNsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[~df.AQI_calculated.isna()].AQI_bucket_calculated.value_counts()"
      ],
      "metadata": {
        "id": "lJbBxlVTE42R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df[[\"PM2.5_SubIndex\", \"PM10_SubIndex\", \"SO2_SubIndex\", \"NOx_SubIndex\",\"NH3_SubIndex\", \"CO_SubIndex\", \"O3_SubIndex\"]]\n",
        "Y=df['AQI_calculated']\n",
        "X.tail()"
      ],
      "metadata": {
        "id": "B9wkgUIKRNzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.tail()\n",
        "# the AQI column is the target column"
      ],
      "metadata": {
        "id": "iTNAE-O3RR7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "d2kgjkD5RTjf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = df[[\"PM2.5_SubIndex\", \"PM10_SubIndex\", \"SO2_SubIndex\", \"NOx_SubIndex\",\"NH3_SubIndex\", \"CO_SubIndex\", \"O3_SubIndex\"]]\n",
        "Y2 = df[\"AQI_calculated\"]\n",
        "# Splitting the data into independent and dependent columns for classification"
      ],
      "metadata": {
        "id": "uQSjNVxZRWCg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AQI_bucket_calculated'].value_counts()"
      ],
      "metadata": {
        "id": "9VqAKrgsRX2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, Y2, test_size=0.33)\n",
        "# Splitting the data into training and testing data"
      ],
      "metadata": {
        "id": "GfWUKo9NRZkB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the model on train data\n",
        "RF=RandomForestClassifier().fit(X_train2,Y_train2)\n",
        "#predict on train\n",
        "train_preds4 = RF.predict(X_train2)\n",
        "#accuracy on train\n",
        "print(\"Model accuracy on train is: \", accuracy_score(Y_train2, train_preds4))\n",
        "\n",
        "#predict on test\n",
        "test_preds4 = RF.predict(X_test2)\n",
        "#accuracy on test\n",
        "print(\"Model accuracy on test is: \", accuracy_score(Y_test2, test_preds4))\n",
        "print('-'*50)\n",
        "\n",
        "# Kappa Score\n",
        "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test2,test_preds4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dbgyi5DtRPni",
        "outputId": "b8dbcfe0-e1a5-47b0-d2c4-1fdb95eaa389"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy on train is:  1.0\n",
            "Model accuracy on test is:  0.5834188384978453\n",
            "--------------------------------------------------\n",
            "KappaScore is:  0.5775912355195565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the model on train data\n",
        "DT2 = DecisionTreeClassifier().fit(X_train2,Y_train2)\n",
        "\n",
        "#predict on train\n",
        "train_preds3 = DT2.predict(X_train2)\n",
        "#accuracy on train\n",
        "print(\"Model accuracy on train is: \", accuracy_score(Y_train2, train_preds3))\n",
        "\n",
        "#predict on test\n",
        "test_preds3 = DT2.predict(X_test2)\n",
        "#accuracy on test\n",
        "print(\"Model accuracy on test is: \", accuracy_score(Y_test2, test_preds3))\n",
        "print('-'*50)\n",
        "\n",
        "# Kappa Score\n",
        "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test2,test_preds3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_SkHXYBEWEF-",
        "outputId": "d66d2fc7-fc25-403f-b27b-03e975e1b62c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy on train is:  1.0\n",
            "Model accuracy on test is:  0.8280320131335933\n",
            "--------------------------------------------------\n",
            "KappaScore is:  0.8256248881618611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DT2.predict([[7.4,47.7,78.182,100,60,35,45]])\n",
        "# Predictions on random values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BA7GfNDfSMCX",
        "outputId": "dffd2220-0863-430b-bd27-588c5eb6463c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([49.])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RF.predict([[7.4,47.7,78.182,100,60,35,45]])\n",
        "# Predictions on random values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pUVqzBJfWddh",
        "outputId": "763e8391-bc6c-4a20-de2b-1c3804ea14cf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([20.])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(DT2, 'decision_tree_model.pkl')"
      ],
      "metadata": {
        "id": "VS5ECIPs79bN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}